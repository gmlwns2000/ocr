{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latium\n",
    "Latium Project 2019. Written by Heejun Lee\n",
    "# Compile\n",
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ainl\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "import gc\n",
    "import util\n",
    "import datetime\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.models.vgg as vgg\n",
    "\n",
    "import display\n",
    "import TFBoard\n",
    "import _pickle as cPickle\n",
    "\n",
    "from coco_text_dataset import coco_text_dataset\n",
    "\n",
    "def in_notebook():\n",
    "    return 'ipykernel' in sys.modules\n",
    "\n",
    "if in_notebook():\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing is passed. running on notbook\n",
      "parsed option: Namespace(b1=0.5, b2=0.999, batch_size=2, bbox_count=1, file='C:\\\\Users\\\\AinL\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0c0112fe-720c-4848-b29f-b6c251fa3228.json', img_size=448, latent_dim=512, load=False, lr=0.0002, n_cpu=16, strings=[], style_dim=32, text_dim=196)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='size of the batches')\n",
    "parser.add_argument('--batch_update', type=int, default=8, help='size of the batches')\n",
    "parser.add_argument('--gan_update', type=int, default=1, help='size of the batches')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='adam: learning rate')\n",
    "parser.add_argument('--lr_update', default=False, action='store_true', help='lupdate learning rate')\n",
    "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--n_cpu', type=int, default=16, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--bbox_count', type=int, default=1, help='bbox count')\n",
    "parser.add_argument('--text_dim', type=int, default=196, help='text embeding dim')\n",
    "parser.add_argument('--style_dim', type=int, default=32, help='style dim')\n",
    "parser.add_argument('--latent_dim', type=int, default=512, help='latent dim')\n",
    "parser.add_argument('--img_size', type=int, default=448, help='image size')\n",
    "parser.add_argument('--vgg_depth', type=int, default=10, help='image size')\n",
    "parser.add_argument('--save_interval', type=int, default=300, help='image size')\n",
    "parser.add_argument('--pic_interval', type=int, default=120, help='image size')\n",
    "parser.add_argument('--load', default=False, action='store_true', help='load from saved checkpoint')\n",
    "parser.add_argument('--load_data', default=False, action='store_true', help='load data from saved cache')\n",
    "parser.add_argument('--no_save', default=False, action='store_true', help='load data from saved cache')\n",
    "parser.add_argument('--cfg_genX', default='3,4,23,8', help='delimited list input', type=str)\n",
    "parser.add_argument('--cfg_genZ', default='3,4,23,8', help='delimited list input', type=str)\n",
    "\n",
    "if in_notebook():\n",
    "    print(\"parsing is passed. running on notbook\")\n",
    "    parser.add_argument(\n",
    "        'strings',\n",
    "        metavar='STRING',\n",
    "        nargs='*',\n",
    "        help='String for searching',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            '-f',\n",
    "            '--file',\n",
    "            help='Path for input file. First line should contain number of lines to search in'\n",
    "        )\n",
    "    opt = parser.parse_args()\n",
    "else:\n",
    "    opt = parser.parse_args()\n",
    "opt.cfg_genX = [int(item) for item in opt.cfg_genX.split(',')]\n",
    "opt.cfg_genZ = [int(item) for item in opt.cfg_genZ.split(',')]\n",
    "if len(opt.cfg_genX) != 4 or len(opt.cfg_genZ) != 4:\n",
    "    raise Exception('cfg must be len 4')\n",
    "print(\"parsed option:\", opt)\n",
    "\n",
    "opt.cuda = True if torch.cuda.is_available() else False\n",
    "if opt.cuda:\n",
    "    device_cuda = torch.device('cuda:0')\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def calc_code_dim(opt):\n",
    "    return (5 + opt.text_dim + opt.style_dim) * opt.bbox_count + opt.latent_dim\n",
    "\n",
    "def getTimeStamp():\n",
    "    timestemp = time.strftime(R\"%m-%d_%H-%M-%S\", time.localtime())\n",
    "    return timestemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        size = x.size()\n",
    "        if len(size) == 4:\n",
    "            x = x.view(-1, size[1] * size[2] * size[3])\n",
    "        return x\n",
    "is_debug = True\n",
    "\n",
    "class Print(nn.Module):\n",
    "    def __init__(self, msg='message'):\n",
    "        super().__init__()\n",
    "        self.msg = msg\n",
    "    def forward(self, x):\n",
    "        global is_debug\n",
    "        if is_debug:\n",
    "            print(\"Module Debug!\", self.msg, \"size:\", x.size())\n",
    "        return x\n",
    "\n",
    "class Logger():\n",
    "    def __init__(self, logdir='./temp', outputLimit=32):\n",
    "        self.logdir = logdir\n",
    "        self.stack = 0\n",
    "        self.outputLimit = outputLimit\n",
    "        self.startTime = datetime.datetime.now()\n",
    "        self.tfboard = None\n",
    "    \n",
    "    def print(self, msg):\n",
    "        if self.stack > self.outputLimit:\n",
    "            display.clear()\n",
    "            self.stack = 0\n",
    "        self.stack += 1\n",
    "        timeMsg = str(datetime.datetime.now()-self.startTime)\n",
    "        print(\"[{}] {}\".format(timeMsg, msg))\n",
    "    \n",
    "    def log_image(self, dic, global_step=None):\n",
    "        if self.tfboard is None:\n",
    "            self.tfboard = TFBoard.Tensorboard(self.logdir)\n",
    "            self.print('tfboard inited: ' + self.logdir)\n",
    "        for k in dic:\n",
    "            self.tfboard.log_image(k, dic[k], global_step)\n",
    "        \n",
    "    def log(self, scalarDict, global_step=None):\n",
    "        if self.tfboard is None:\n",
    "            self.tfboard = TFBoard.Tensorboard(self.logdir)\n",
    "            self.print('tfboard inited: ' + self.logdir)\n",
    "        output = \"\"\n",
    "        for i, k in enumerate(sorted(scalarDict.keys())):\n",
    "            v = scalarDict[k]\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.detach().cpu().numpy()\n",
    "            if global_step is not None:\n",
    "                self.tfboard.log_scalar(k, v, global_step, flush=False)\n",
    "            t = k+\" : \"+str(v)\n",
    "            if i!=0:\n",
    "                t+=', \\n'\n",
    "            output = t+output\n",
    "        if global_step is not None:\n",
    "            output = \"(\" + str(global_step) + \" steps) \" + output\n",
    "        if self.tfboard is not None:\n",
    "            self.tfboard.flush()\n",
    "        self.print(output)\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "    \n",
    "    def to(self, device):\n",
    "        for d in self.data:\n",
    "            d.to(device)\n",
    "    \n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "class VGG16Feature(nn.Module):\n",
    "    def __init__(self, depth=10000):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg.vgg16(pretrained=True)\n",
    "        self.depth = depth\n",
    "        print(\"aaaaaaaaaaaaaa\", self.vgg.features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vgg.features[:self.depth](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, bnorm=nn.BatchNorm2d, relu = nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "\n",
    "        if out_channel % 4 != 0:\n",
    "            raise Exception('ResBlock output should divide by 4')\n",
    "        \n",
    "        bottle = int(out_channel//4)\n",
    "        self.relu = relu\n",
    "        self.bnorm = bnorm\n",
    "        self.reluF = relu()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, bottle, kernel_size=1, bias=False),\n",
    "            bnorm(bottle),\n",
    "            relu(),\n",
    "\n",
    "            nn.Conv2d(bottle, bottle, kernel_size=3, padding=1, bias=False, stride=stride),\n",
    "            bnorm(bottle),\n",
    "            relu(),\n",
    "\n",
    "            nn.Conv2d(bottle, out_channel, kernel_size=1, bias=False),\n",
    "            bnorm(out_channel),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False, stride=stride),\n",
    "                bnorm(out_channel),\n",
    "            )\n",
    "    \n",
    "    def forward(self, xR):\n",
    "        #ResBlockForward\n",
    "        x = self.net(xR)\n",
    "#         print(x.size(), xR.size())\n",
    "        shortcut = self.shortcut(xR)\n",
    "#         print(shortcut.size())\n",
    "        x += shortcut\n",
    "        x = self.reluF(x)\n",
    "        return x\n",
    "\n",
    "class ResBlockBackward(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, relu=nn.LeakyReLU, bnorm=nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "\n",
    "        if out_channel % 4 != 0:\n",
    "            raise Exception('ResBlock output should divide by 4')\n",
    "\n",
    "        bottle = int(out_channel/4)\n",
    "        self.relu = relu\n",
    "        self.bnorm = bnorm\n",
    "        self.reluF = relu()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(out_channel, bottle, kernel_size=1, bias=False),\n",
    "            bnorm(bottle),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(bottle, bottle, kernel_size=3, bias=False, padding=1),\n",
    "            bnorm(bottle),\n",
    "            relu(),\n",
    "            nn.UpsamplingNearest2d(scale_factor=stride),\n",
    "            \n",
    "            nn.Conv2d(bottle, in_channel, kernel_size=1, bias=False),\n",
    "            bnorm(in_channel),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if(in_channel != out_channel or stride != 1):\n",
    "            self.shortcut = nn.Sequential(\n",
    "                #nn.ConvTranspose2d(out_channel, in_channel, kernel_size=1, stride=stride, bias=False, output_padding=1),\n",
    "                nn.Conv2d(out_channel, in_channel, kernel_size=1, bias=False),\n",
    "                bnorm(in_channel),\n",
    "                nn.UpsamplingNearest2d(scale_factor=stride),\n",
    "            )\n",
    "    \n",
    "    def forward(self, xR):\n",
    "        x = self.net(xR)\n",
    "        x += self.shortcut(xR)\n",
    "        x = self.reluF(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator X (Image)\n",
    "\n",
    "input: `code[bbox(con), text(con), style(con), latent]` `dim {N, ((5+text_dim)*bbox_count+style_dim), 14, 14}`\n",
    "\n",
    "output: `image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenX(nn.Module):\n",
    "    def __init__(self, cfg=[3,4,23,8]):\n",
    "        super(GenX, self).__init__()\n",
    "        \n",
    "        def relu():\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        def bnorm(ch):\n",
    "            return nn.BatchNorm2d(ch, 0.8)\n",
    "        \n",
    "        def resBlockBackward(repeat, in_channel, out_channel, stride=2):\n",
    "            layers = []\n",
    "            for _ in range(repeat-1):\n",
    "                layers.append(ResBlockBackward(in_channel=out_channel, out_channel=out_channel, stride=1, relu=relu, bnorm=bnorm))\n",
    "            layers.append(ResBlockBackward(in_channel=in_channel, out_channel=out_channel, stride=stride, relu=relu, bnorm=bnorm))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        self.code_dim = calc_code_dim(opt)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.code_dim),\n",
    "            #l1\n",
    "            nn.Conv2d(self.code_dim, 1024, kernel_size=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "\n",
    "            nn.Conv2d(512, 1024, kernel_size=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(512, 1024, kernel_size=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(512, 2048, kernel_size=1, bias=False),\n",
    "            bnorm(2048),\n",
    "            relu(),\n",
    "\n",
    "            #upsample 14 > 28\n",
    "            #resblock cfg[3]=8\n",
    "            resBlockBackward(8, 1024, 2048),\n",
    "            \n",
    "            #upsample 28 > 56\n",
    "            #resblock cfg[2]=23\n",
    "            resBlockBackward(23, 512, 1024),\n",
    "            \n",
    "            #upsample 56 > 112\n",
    "            #resblock cfg[1]=4\n",
    "            resBlockBackward(4, 256, 512),\n",
    "            \n",
    "            #resblock cfg[0]=3\n",
    "            resBlockBackward(3, 64, 256, stride=1),            \n",
    "            \n",
    "            #upsample 112 > 448\n",
    "            nn.UpsamplingNearest2d(scale_factor=4),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, padding=3),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def report(self):\n",
    "        return str(self.net)\n",
    "    \n",
    "    def forward(self, bbox, text, style, latent):\n",
    "        x = torch.cat((bbox, text, style, latent), 1)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Z (Code)\n",
    "\n",
    "input: `image`\n",
    "\n",
    "output: `code[bbox(con), text(con), style(con), latent]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenZ(nn.Module):\n",
    "    def __init__(self, cfg=[3,4,23,8]):\n",
    "        super(GenZ, self).__init__()\n",
    "        \n",
    "        def relu():\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        def bnorm(ch):\n",
    "            return nn.BatchNorm2d(ch, 0.8)\n",
    "        \n",
    "        def resBlock(repeat, in_channel, out_channel, stride=2):\n",
    "            layers = []\n",
    "            layers.append(ResBlock(in_channel=in_channel, out_channel=out_channel, stride=stride, relu=relu, bnorm=bnorm))\n",
    "            for _ in range(repeat-1):\n",
    "                layers.append(ResBlock(in_channel=out_channel, out_channel=out_channel, stride=1, relu=relu, bnorm=bnorm))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        self.code_dim = calc_code_dim(opt)    \n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            #downsample 112 < 448\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            bnorm(64),\n",
    "            relu(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            #resblock cfg[0]=3\n",
    "            resBlock(cfg[0], 64, 256, stride=1),\n",
    "            \n",
    "            #downsample 56 < 112\n",
    "            #resblock cfg[1]=4\n",
    "            resBlock(cfg[1], 256, 512),\n",
    "            \n",
    "            #downsample 28 < 56\n",
    "            #resblock cfg[2]=23\n",
    "            resBlock(cfg[2], 512, 1024),\n",
    "\n",
    "            #downsample 14 < 28\n",
    "            #resblock cfg[3]=8\n",
    "            resBlock(cfg[3], 1024, 2048),\n",
    "            \n",
    "            #l1\n",
    "            nn.Conv2d(2048, 512, kernel_size=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=1, bias=False),\n",
    "            bnorm(512),\n",
    "            relu(),\n",
    "\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1, bias=False),\n",
    "            bnorm(1024),\n",
    "            relu(),\n",
    "            \n",
    "            nn.Conv2d(1024, self.code_dim, kernel_size=1, bias=False),\n",
    "            # nn.BatchNorm2d(self.code_dim, 0.8),\n",
    "            #nn.LeakyReLU(inplace=True),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def report(self):\n",
    "        return str(self.net)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        bbox = x[:,0:5*opt.bbox_count,:,:]\n",
    "        text = x[:,5*opt.bbox_count:(5+opt.text_dim)*opt.bbox_count,:,:]\n",
    "        style = x[:,(5+opt.text_dim)*opt.bbox_count:(5+opt.text_dim+opt.style_dim)*opt.bbox_count,:,:]\n",
    "        latent = x[:,(5+opt.text_dim+opt.style_dim)*opt.bbox_count:self.code_dim,:,:]\n",
    "        return bbox, text, style, latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator X (Image)\n",
    "InfoGAN is applied.\n",
    "\n",
    "input: `image`\n",
    "\n",
    "output: `valid(1), bbox(5,con), text(opt.text_dim,con), style(opt.style_dim,con)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscX, self).__init__()\n",
    "        \n",
    "        def relu():\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        def bnorm(ch):\n",
    "            return nn.BatchNorm2d(ch, 0.8)\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [   nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
    "                        relu(),\n",
    "                        nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(bnorm(out_filters))\n",
    "            return nn.Sequential(*block)\n",
    "\n",
    "        self.net_front = nn.Sequential(\n",
    "            discriminator_block(3, 32, bn=False),\n",
    "            discriminator_block(32, 64),\n",
    "            discriminator_block(64, 128),\n",
    "            discriminator_block(128, 256),\n",
    "            discriminator_block(256, 512),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2**5\n",
    "        last_ch = 512\n",
    "\n",
    "        # Output layers\n",
    "        self.net_valid = nn.Sequential(\n",
    "            Flat(),\n",
    "            nn.Linear(last_ch*ds_size**2, 1)\n",
    "        )\n",
    "        self.net_bbox = nn.Sequential(\n",
    "            nn.Conv2d(last_ch, opt.bbox_count * 5, kernel_size=1)\n",
    "        )\n",
    "        self.net_text = nn.Sequential(\n",
    "            nn.Conv2d(last_ch, opt.text_dim * opt.bbox_count, kernel_size=1)\n",
    "        )\n",
    "        self.net_style = nn.Sequential(\n",
    "            nn.Conv2d(last_ch, opt.style_dim * opt.bbox_count, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_front(x)\n",
    "        valid = self.net_valid(x)\n",
    "        bbox = self.net_bbox(x)\n",
    "        text = self.net_text(x)\n",
    "        style = self.net_style(x)\n",
    "        return valid, bbox, text, style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Z (Code)\n",
    "\n",
    "input: `code`\n",
    "\n",
    "output: `valid(1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscZ, self).__init__()\n",
    "        \n",
    "        def relu():\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        def bnorm(ch):\n",
    "            return nn.BatchNorm2d(ch, 0.8)\n",
    "        \n",
    "        dim = calc_code_dim(opt)\n",
    "        ds_size = opt.img_size // 2**5\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, 256, kernel_size=1),\n",
    "            relu(),\n",
    "            bnorm(256),\n",
    "\n",
    "            nn.Conv2d(256, 128, kernel_size=1),\n",
    "            relu(),\n",
    "            bnorm(128),\n",
    "\n",
    "            Flat(),\n",
    "            \n",
    "            nn.Linear(128*ds_size**2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, bbox, text, style, latent):\n",
    "        if text is None and style is None and latent is None:\n",
    "            x=bbox\n",
    "        else:\n",
    "            x=torch.cat((bbox, text, style, latent), 1)\n",
    "        return self.net(x)\n",
    "\n",
    "#**note** Disc Opt Rule: MSE to 0(fake) MSE to 1(real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime\n",
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "loading annotations into memory...\n",
      "cache loading...\n",
      "cache loaded\n",
      "load total 0:00:01.645371\n",
      "cached!\n",
      "loaded!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #=====================================================\n",
    "    # load data\n",
    "    #=====================================================\n",
    "    if opt.load_data and os.path.exists('latium.data.cache'):\n",
    "        print('read data cache...')\n",
    "        with open('latium.data.cache', 'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "    else:\n",
    "        print('write data cache...')\n",
    "        data = coco_text_dataset( \\\n",
    "                     batchW=opt.img_size, batchH=opt.img_size,\n",
    "                     outputGridW=opt.img_size//2**5, outputGridH=opt.img_size//2**5,\n",
    "                     catIds=[('legibility','legible')],\n",
    "                     minSize=[0,14],\n",
    "                     textDim=opt.text_dim, styleDim=opt.style_dim, latentDim=opt.latent_dim,\n",
    "                     bboxCount=opt.bbox_count, ignoreCache=False)\n",
    "        with open('latium.data.cache', 'wb') as f:\n",
    "            cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-83af1f8ea8b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#init logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logger inited'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Logger' is not defined"
     ]
    }
   ],
   "source": [
    "#=========================================================\n",
    "# main program\n",
    "#=========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    #init logger\n",
    "    logger = Logger()\n",
    "    logger.print('logger inited')\n",
    "    \n",
    "    #=====================================================\n",
    "    # init data\n",
    "    #=====================================================\n",
    "    \n",
    "    load_model = opt.load and os.path.exists('latium.model')\n",
    "    logger.print('initializing...')\n",
    "    #models\n",
    "    genX = GenX(cfg=opt.cfg_genX)\n",
    "    genZ = GenZ(cfg=opt.cfg_genZ)\n",
    "    discX = DiscX()\n",
    "    discZ = DiscZ()\n",
    "    if load_model:\n",
    "        logger.print('load from disk')\n",
    "        state = torch.load('latium.model')\n",
    "        #models\n",
    "        genX.load_state_dict(state['genX'])\n",
    "        genZ.load_state_dict(state['genZ'])\n",
    "        discX.load_state_dict(state['discX'])\n",
    "        discZ.load_state_dict(state['discZ'])\n",
    "    if opt.cuda:\n",
    "        for i in [genX, genZ, discX, discZ]:\n",
    "            i.cuda()\n",
    "    logger.print('genX')\n",
    "#     logger.print(genX.report())\n",
    "    logger.print('genZ')\n",
    "#     logger.print(genZ.report())\n",
    "    #vgg\n",
    "    logger.print('load vgg')\n",
    "    featureNet = VGG16Feature(depth = opt.vgg_depth)\n",
    "    featureNet.cuda()\n",
    "    featureNet.eval()\n",
    "    #buffers\n",
    "    fake_X_buffer = ReplayBuffer()\n",
    "    fake_Z_buffer = ReplayBuffer()\n",
    "    #optimizers\n",
    "    optCycle = torch.optim.Adam(itertools.chain(genX.parameters(), genZ.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "    optDz = torch.optim.Adam(discZ.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "    optDx = torch.optim.Adam(discX.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "    optInfo = torch.optim.Adam(itertools.chain(genX.parameters(), discX.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "#     optBbox = torch.optim.Adam(genZ.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "    #trian\n",
    "    train_step = 0\n",
    "    logger.logdir = os.path.join(r\"F:\\Library\\ocr\\temp\", getTimeStamp())\n",
    "    \n",
    "    if load_model:\n",
    "        #buffers\n",
    "        fake_X_buffer = state['fake_X_buffer']\n",
    "        fake_Z_buffer = state['fake_Z_buffer']\n",
    "#         if opt.cuda:\n",
    "#             fake_Z_buffer.to(device_cuda)\n",
    "#             fake_X_buffer.to(device_cuda)\n",
    "        #optimizers\n",
    "        optCycle.load_state_dict(state['optCycle'])\n",
    "        optDz.load_state_dict(state['optDz'])\n",
    "        optDx.load_state_dict(state['optDx'])\n",
    "        optInfo.load_state_dict(state['optInfo'])\n",
    "#         optBbox.load_state_dict(state['optBbox'])\n",
    "        #trian\n",
    "        train_step = state['train_step']\n",
    "        logger.logdir = state['logger_logdir']\n",
    "    else:\n",
    "        for i in [genX, genZ, discX, discZ]:\n",
    "            i.apply(weights_init_normal)\n",
    "#     discX = DiscX()\n",
    "#     discX.apply(weights_init_normal)\n",
    "#     optCycle = torch.optim.Adam(itertools.chain(genX.parameters(), genZ.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "#     optDx = torch.optim.Adam(discX.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "#     logger.print('disc x cleared!')\n",
    "    if opt.lr_update:\n",
    "        logger.print('update learning rate')\n",
    "        for o in [optCycle, optDz, optDz, optInfo]:\n",
    "            for param_group in o.param_groups:\n",
    "                param_group['lr'] = opt.lr\n",
    "    for i in [genX, genZ, discX, discZ]:\n",
    "        i.train()\n",
    "    if load_model:\n",
    "        del state\n",
    "    logger.print('model inited')\n",
    "    \n",
    "    #=====================================================\n",
    "    # init train\n",
    "    #=====================================================\n",
    "    \n",
    "    #losses\n",
    "    lossGAN = torch.nn.MSELoss()\n",
    "    lossCycle = torch.nn.L1Loss()\n",
    "    lossIdentity = torch.nn.L1Loss()\n",
    "    lossInfoCon = nn.MSELoss()\n",
    "    lossInfoCat = nn.CrossEntropyLoss()\n",
    "#     lossMSE = nn.MSELoss()\n",
    "    #lambdas\n",
    "    lambda_cat = 1\n",
    "    lambda_con = 0.1\n",
    "    target_real = Variable(Tensor(opt.batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "    target_fake = Variable(Tensor(opt.batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "    #move to cuda\n",
    "    if opt.cuda:\n",
    "        for i in [lossCycle, lossInfoCat, lossInfoCon, lossGAN]:\n",
    "            i.cuda()\n",
    "    time_log = 0\n",
    "    time_all = 0\n",
    "    time_last_img = 0\n",
    "    time_last_save = 0\n",
    "    batch_thread = util.ThreadBuffer()\n",
    "    def batchGet(count):\n",
    "        batch = data.batch(count)\n",
    "        batch_image = Tensor(batch['img'])\n",
    "        batch_image = batch_image.permute(0, 3, 1, 2)\n",
    "        batch_image = (batch_image.float() - 127.5)/127.5\n",
    "        batch_bbox = Tensor(batch['bbox'])\n",
    "        batch_text = Tensor(batch['text'])\n",
    "        batch_style = Tensor(batch['style'])\n",
    "        batch_latent = Tensor(batch['latent'])\n",
    "        return batch, batch_image, batch_bbox, batch_text, batch_style, batch_latent\n",
    "    logger.print('values inited')\n",
    "    \n",
    "    #=====================================================\n",
    "    # train loop\n",
    "    #=====================================================\n",
    "    loss_D_Z = loss_bbox = loss_info = loss_D_X = loss_G = None\n",
    "    forward_step = 0\n",
    "    gan_forward_step = 0\n",
    "    while True:\n",
    "        log_dict = {}\n",
    "        #=================================================\n",
    "        # Batch: Read Data\n",
    "        #=================================================\n",
    "        \n",
    "        s_all = s = time.time()\n",
    "        \n",
    "        update_parameter = forward_step != 0 and forward_step % opt.batch_update == 0\n",
    "        if update_parameter:\n",
    "            logger.print(\"update parameter\")\n",
    "        else:\n",
    "            logger.print(\"forwarding... {}/{}\".format(forward_step%opt.batch_update, opt.batch_update))\n",
    "        forward_step += 1\n",
    "        \n",
    "        for _ in range(opt.gan_update):\n",
    "            s_batch = time.time()\n",
    "            \n",
    "            update_gan = gan_forward_step != 0 and gan_forward_step % opt.batch_update == 0\n",
    "#             if update_gan:\n",
    "#                 logger.print(\"update gan\")\n",
    "#             else:\n",
    "#                 logger.print(\"forward gan\")\n",
    "            gan_forward_step += 1\n",
    "            \n",
    "            batch, batch_image, batch_bbox, batch_text, batch_style, batch_latent = \\\n",
    "                batch_thread.get(batchGet, [opt.batch_size])\n",
    "\n",
    "            time_batch = time.time()-s_batch\n",
    "\n",
    "            #=================================================\n",
    "            # Cycle: Train Generator\n",
    "            # https://github.com/aitorzip/PyTorch-CycleGAN/\n",
    "            #=================================================\n",
    "            \n",
    "            #==== Identity loss\n",
    "            # should skipped?\n",
    "\n",
    "            #==== GAN loss\n",
    "            fake_Z_bbox, fake_Z_text, fake_Z_style, fake_Z_latent = genZ(batch_image)\n",
    "            pred_fake = discZ(fake_Z_bbox, fake_Z_text, fake_Z_style, fake_Z_latent)\n",
    "            loss_GAN_X2Z = lossGAN(pred_fake, target_real)\n",
    "\n",
    "            fake_X_now = fake_X = genX(batch_bbox, batch_text, batch_style, batch_latent)\n",
    "            pred_fake, _, _, _ = discX(fake_X)\n",
    "            loss_GAN_Z2X = lossGAN(pred_fake, target_real)\n",
    "\n",
    "            #==== Cycle loss\n",
    "            recovered_X = genX(fake_Z_bbox, fake_Z_text, fake_Z_style, fake_Z_latent)\n",
    "            recovered_X_feature = featureNet(recovered_X)\n",
    "            batch_image_feature = featureNet(batch_image)\n",
    "            loss_cycle_XZX_content = torch.mean(torch.pow(recovered_X_feature-batch_image_feature, 2)) * 1\n",
    "#             print('hello', recovered_X_feature.size(), loss_cycle_XZX_content)\n",
    "            loss_cycle_XZX = lossCycle(recovered_X, batch_image) * 10.0\n",
    "\n",
    "            recovered_Z = genZ(fake_X)\n",
    "            loss_cycle_ZXZ = lossCycle(torch.cat(recovered_Z, 1), torch.cat((batch_bbox, batch_text, batch_style, batch_latent), 1))*10.0\n",
    "            \n",
    "            #==== Bbox loss\n",
    "            batch_prob_mask = batch_bbox[:,4:5,:,:]\n",
    "            batch_prob_noobj_mask = (batch_prob_mask - 1) * (-1)\n",
    "            fake_Z_prob_mask = fake_Z_bbox[:,4:5,:,:]\n",
    "            loss_bbox_obj = torch.sum(torch.pow(batch_prob_mask - fake_Z_prob_mask, 2) * \\\n",
    "                                batch_prob_mask)\n",
    "            loss_bbox_noobj = 0.5 * torch.sum(torch.pow(batch_prob_mask - fake_Z_prob_mask, 2) *\\\n",
    "                                        batch_prob_noobj_mask)\n",
    "\n",
    "            fake_Z_bbox_loc = fake_Z_bbox[:,0:2,:,:]\n",
    "            batch_bbox_loc = batch_bbox[:,0:2,:,:]\n",
    "            loss_bbox_loc_mse = 5 * torch.sum(torch.pow(batch_bbox_loc-fake_Z_bbox_loc, 2) * \\\n",
    "                                 batch_prob_mask)\n",
    "\n",
    "            fake_Z_bbox_size = fake_Z_bbox[:,2:4,:,:]\n",
    "            batch_bbox_size = batch_bbox[:,2:4,:,:]\n",
    "            loss_bbox_size_mse = 5 * torch.sum(torch.pow(batch_bbox_size-\\\n",
    "                                                         fake_Z_bbox_size, 2) * batch_prob_mask)\n",
    "            \n",
    "            #TODO: need add text loss\n",
    "\n",
    "            loss_bbox = loss_bbox_obj + loss_bbox_noobj + loss_bbox_loc_mse + loss_bbox_size_mse\n",
    "            \n",
    "            #==== Total loss\n",
    "            _loss_G = loss_GAN_X2Z + loss_GAN_Z2X + loss_cycle_XZX + loss_cycle_ZXZ + loss_cycle_XZX_content + loss_bbox\n",
    "            if loss_G is None:\n",
    "                loss_G = _loss_G\n",
    "#                 print('push lossG')\n",
    "            else:\n",
    "                _loss_G.data += loss_G.data\n",
    "                loss_G = _loss_G\n",
    "#                 print('stack lossG')\n",
    "            \n",
    "            optCycle.zero_grad()\n",
    "            \n",
    "            if update_gan:\n",
    "                loss_G.data /= opt.batch_update\n",
    "                loss_G_scalar = loss_G.item()\n",
    "#                 log_dict['loss/loss_G'] = loss_G_scalar\n",
    "            loss_G.backward()\n",
    "            \n",
    "            if update_gan:\n",
    "                optCycle.step()\n",
    "                loss_G = None\n",
    "#                 print('claer loss_G')\n",
    "\n",
    "        time_cycle = time.time()-s\n",
    "\n",
    "        #=================================================\n",
    "        # Cycle: train Disc X\n",
    "        #=================================================\n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "        # Real loss\n",
    "        pred_real, _, _, _ = discX(batch_image)\n",
    "        loss_D_real = lossGAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_X = fake_X_buffer.push_and_pop(fake_X.detach())\n",
    "        pred_fake, _, _, _ = discX(fake_X)\n",
    "        loss_D_fake = lossGAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        _loss_D_X = (loss_D_real + loss_D_fake)*0.5\n",
    "        if loss_D_X is None:\n",
    "            loss_D_X = _loss_D_X\n",
    "        else:\n",
    "            _loss_D_X.data += loss_D_X.data\n",
    "            loss_D_X = _loss_D_X\n",
    "\n",
    "        optDx.zero_grad()\n",
    "\n",
    "        if update_parameter:\n",
    "            loss_D_X.data /= opt.batch_update\n",
    "        loss_D_X.backward()\n",
    "\n",
    "        if update_parameter:\n",
    "            optDx.step()\n",
    "        \n",
    "        time_discX = time.time() - s\n",
    "\n",
    "        #=================================================\n",
    "        # Cycle: train Disc Z\n",
    "        #=================================================\n",
    "        \n",
    "        s = time.time()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = discZ(batch_bbox, batch_text, batch_style, batch_latent)\n",
    "        loss_D_real = lossGAN(pred_real, target_real)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_Z_code = fake_Z_buffer.push_and_pop(\\\n",
    "            torch.cat((fake_Z_bbox.detach(), fake_Z_text.detach(), fake_Z_style.detach(), fake_Z_latent.detach()), 1))\n",
    "        pred_fake = discZ(fake_Z_code, None, None, None)\n",
    "        loss_D_fake = lossGAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        _loss_D_Z = (loss_D_real + loss_D_fake)*0.5\n",
    "        if loss_D_Z is None:\n",
    "            loss_D_Z = _loss_D_Z\n",
    "        else:\n",
    "            _loss_D_Z.data += loss_D_Z.data\n",
    "            loss_D_Z = _loss_D_Z\n",
    "\n",
    "        optDz.zero_grad()\n",
    "\n",
    "        if update_parameter:\n",
    "            loss_D_Z.data /= opt.batch_update\n",
    "        loss_D_Z.backward()\n",
    "\n",
    "        if update_parameter:\n",
    "            optDz.step()\n",
    "        \n",
    "        time_discZ = time.time() - s\n",
    "        \n",
    "        #=================================================\n",
    "        # Info: train Info GenX\n",
    "        #=================================================\n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "        optInfo.zero_grad()\n",
    "        \n",
    "        # Sample noise, labels and code as generator input\n",
    "        _, pred_bbox, pred_text, pred_style = discX(genX(batch_bbox, batch_text, batch_style, batch_latent))\n",
    "        \n",
    "        _loss_info = lambda_con * (lossInfoCon(pred_bbox, batch_bbox) + \\\n",
    "                                  lossInfoCon(pred_text, batch_text) + \\\n",
    "                                  lossInfoCon(pred_style, batch_style)) * 0.33\n",
    "\n",
    "        if loss_info is None:\n",
    "            loss_info = _loss_info\n",
    "        else:\n",
    "            _loss_info.data += loss_info.data\n",
    "            loss_info = _loss_info\n",
    "\n",
    "        optInfo.zero_grad()\n",
    "\n",
    "        if update_parameter:\n",
    "            loss_info.data /= opt.batch_update\n",
    "        loss_info.backward()\n",
    "\n",
    "        if update_parameter:\n",
    "            optInfo.step()\n",
    "        \n",
    "        time_info = time.time() - s\n",
    "        \n",
    "        #=================================================\n",
    "        # YOLO: train BBox\n",
    "        #=================================================\n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "#         fake_Z_bbox, fake_Z_text, fake_Z_style, fake_Z_latent = genZ(batch_image)\n",
    "        \n",
    "#         batch_prob_mask = batch_bbox[:,4:5,:,:]\n",
    "#         batch_prob_noobj_mask = (batch_prob_mask - 1) * (-1)\n",
    "#         fake_Z_prob_mask = fake_Z_bbox[:,4:5,:,:]\n",
    "#         loss_bbox_obj = torch.sum(torch.pow(batch_prob_mask - fake_Z_prob_mask, 2) * \\\n",
    "#                             batch_prob_mask)\n",
    "#         loss_bbox_noobj = 0.5 * torch.sum(torch.pow(batch_prob_mask - fake_Z_prob_mask, 2) *\\\n",
    "#                                     batch_prob_noobj_mask)\n",
    "        \n",
    "#         fake_Z_bbox_loc = fake_Z_bbox[:,0:2,:,:]\n",
    "#         batch_bbox_loc = batch_bbox[:,0:2,:,:]\n",
    "#         loss_bbox_loc_mse = 5 * torch.sum(torch.pow(batch_bbox_loc-fake_Z_bbox_loc, 2) * \\\n",
    "#                              batch_prob_mask)\n",
    "        \n",
    "#         fake_Z_bbox_size = fake_Z_bbox[:,2:4,:,:]\n",
    "#         batch_bbox_size = batch_bbox[:,2:4,:,:]\n",
    "#         loss_bbox_size_mse = 5 * torch.sum(torch.pow(torch.sqrt(torch.abs(batch_bbox_size))-\\\n",
    "#                                                      torch.sqrt(torch.abs(fake_Z_bbox_size)), 2) * batch_prob_mask)\n",
    "        \n",
    "#         #TODO: need add text loss\n",
    "        \n",
    "#         _loss_bbox = loss_bbox_obj + loss_bbox_noobj + loss_bbox_loc_mse + loss_bbox_size_mse\n",
    "#         if loss_bbox is None:\n",
    "#             loss_bbox = _loss_bbox\n",
    "#         else:\n",
    "#             _loss_bbox.data += loss_bbox.data\n",
    "#             loss_bbox = _loss_bbox\n",
    "\n",
    "#         optBbox.zero_grad()\n",
    "\n",
    "#         if update_parameter:\n",
    "#             loss_bbox.data /= opt.batch_update\n",
    "#         loss_bbox.backward()\n",
    "\n",
    "#         if update_parameter:\n",
    "#             optBbox.step()\n",
    "        \n",
    "        time_bbox = time.time() - s\n",
    "        \n",
    "        #=================================================\n",
    "        # Logging\n",
    "        #=================================================        \n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "        if update_parameter:\n",
    "            def postImg(batch, i=0, cvtBGR=False):\n",
    "                img = batch[i].detach()\n",
    "                img = img * 127.5 + 127.5\n",
    "                img = torch.clamp(img,0,255)\n",
    "                img = img.permute(1,2,0).cpu().numpy().astype(np.uint8)\n",
    "                img = cv2.resize(img, dsize=(opt.img_size, opt.img_size))\n",
    "                if cvtBGR:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                return img\n",
    "            if in_notebook() or time.time()-time_last_img > opt.pic_interval:\n",
    "                real_img = postImg(batch_image)\n",
    "                fake_img = postImg(fake_X_now)\n",
    "                recv_img = postImg(recovered_X)\n",
    "                img = np.concatenate((real_img, fake_img, recv_img), axis=1)\n",
    "                if in_notebook():\n",
    "                    display.vidshow(img, maxSize=(800,400))\n",
    "                logger.log_image({\\\n",
    "                        'img/real_fake_recv' : cv2.cvtColor(img, cv2.COLOR_BGR2RGB),\n",
    "                        }, global_step=train_step)\n",
    "                if ((time_last_img == 0 and train_step == 0 and (not os.path.exists('latium.model'))) or train_step != 0) and \\\n",
    "                    not opt.no_save and time.time()-time_last_save > opt.save_interval:\n",
    "                    logger.print('saving...')\n",
    "                    state = {\n",
    "                        'genX':genX.state_dict(),\n",
    "                        'genZ':genZ.state_dict(),\n",
    "                        'discX':discX.state_dict(),\n",
    "                        'discZ':discZ.state_dict(),\n",
    "                        'fake_X_buffer':fake_X_buffer,\n",
    "                        'fake_Z_buffer':fake_Z_buffer,\n",
    "                        'optCycle':optCycle.state_dict(),\n",
    "                        'optDz':optDz.state_dict(),\n",
    "                        'optDx':optDx.state_dict(),\n",
    "                        'optInfo':optInfo.state_dict(),\n",
    "#                             'optBbox':optBbox.state_dict(),\n",
    "                        'train_step':train_step,\n",
    "                        'logger_logdir':logger.logdir,\n",
    "                    }\n",
    "                    torch.save(state, 'latium.model')\n",
    "                    logger.print(\"saved\")\n",
    "                    del state\n",
    "                    time_last_save = time.time()\n",
    "                time_last_img = time.time()\n",
    "\n",
    "            logger.log({\\\n",
    "                        'loss/loss_G':loss_G_scalar, \n",
    "                        'loss/GAN/X2Z':loss_GAN_X2Z, \n",
    "                        'loss/GAN/Z2X':loss_GAN_Z2X,\n",
    "                        'loss/GAN/cycleXZX':loss_cycle_XZX,\n",
    "                        'loss/GAN/cycleZXZ':loss_cycle_ZXZ,\n",
    "                        'loss/GAN/cycleXZXcontent':loss_cycle_XZX_content,\n",
    "                        'loss/loss_D_Z':loss_D_Z,\n",
    "                        'loss/loss_D_X':loss_D_X,\n",
    "                        'loss/loss_Info':loss_info,\n",
    "                        'loss/loss_bbox':loss_bbox,\n",
    "                        'loss/bbox/loc':loss_bbox_loc_mse,\n",
    "                        'loss/bbox/noobj':loss_bbox_noobj,\n",
    "                        'loss/bbox/obj':loss_bbox_obj,\n",
    "                        'loss/bbox/size':loss_bbox_size_mse,\n",
    "                        'time/cycle':time_cycle,\n",
    "                        'time/batch':time_batch,\n",
    "                        'time/discX':time_discX,\n",
    "                        'time/discZ':time_discZ,\n",
    "                        'time/info':time_info,\n",
    "                        'time/bbox':time_bbox,\n",
    "                        'time/log':time_log,\n",
    "                        'time/all':time_all,\n",
    "                       }, global_step=train_step)\n",
    "            train_step += 1\n",
    "            loss_D_X = loss_D_Z = loss_info = loss_bbox = None\n",
    "            time_log = time.time() - s\n",
    "        del log_dict\n",
    "        time_all = time.time() - s_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.792px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "221.323px",
    "left": "757.667px",
    "right": "20px",
    "top": "84px",
    "width": "602.99px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
